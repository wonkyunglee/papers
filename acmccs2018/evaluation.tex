\section{Evaluation}
이번 섹션에서는 우리가 제안하는 멀웨어 IR 시스템의 성능을 여러 방법으로 평가하여, 앞에서 우리의 시스템의 강점이라고 주장했던 semantic-aware malware retrieval 태스크를 수행하였는지 확인한다. 


\subsection{Implementation and Setup}
\textbf{Datasets. } 
모델의 학습과 평가에 사용된 dataset은 VirusTotal로부터 [언제부터 언제까지] crawling된 샘플들 중 security expert가 검수하여 확진을 내린 샘플들로 구성되어있다. 또한 VirusTotal에서 제공하는 수십개 이상의 AntiVirus 엔진의 탐지결과로부터 Labeling을 자동화 하였다. VirusTotal로부터 각 AntiVirus 엔진들이 탐지해낸 결과를 의미있는 word 단위로 파싱하고, 샘플들로 부터 얻어진 word token들을 대상으로 security expert가 의미있는 토큰과 그렇지 않은 토큰을 선별하는 작업을 수행하였다. 추가로, 의미 있는 토큰에 대해 중요도에 따라 우선순위를 매기도록 하였다. 이를 통해 학습 샘플에 대해 expert가 일일히 수동으로 label을 다는 시간을 줄이면서도 높은 accuracy의 label을 얻을 수 있다. 또한, 하나의 샘플에 대표 레이블과 멀티레이블 두 종류의 레이블을 부여했으며, 멀티 레이블에는 대표 레이블이 포함된다. 

\begin{itemize}
	\item{ \textbf{Dataset 1. PE1300. } VirusTotal로부터 crawling된 샘플들 PE 5만여개 중 security expert가 검수하여 확진을 내린 PE 샘플 1300여개 11종의 labels. 이 중 8개는 대표 레이블이며 대표 레이블에 대한 샘플들의 수는 거의 같다. 즉 대표 레이블에 대한 샘플의 분포는 유니폼하다.
	}
	\item{ \textbf{Dataset 2. APK19000. } VirusTotal로부터 crawling된 샘플들 APK 8만여개 중 security expert가 검수하여 확진을 내린 APK 샘플 2만여개 83종의 labels. 이 중 19개는 대표 레이블이며 대표 레이블에 대한 샘플의 수는 1000개로 같다. PE 데이터셋과 마찬가지로 대표 레이블에 대한 샘플의 분포는 유니폼하다.  
	}
\end{itemize}



\textbf{Hyperparameters. }
- layers, learning rate, train/valid ratio, Label importances, 


\textbf{Hancrafted Feature Extraction}
- Thumbnail
- Size, Entropy
- Call histogram


\subsection{Auxiliary Task Evaluation}
Auxiliary task 의 정확도는 더 안좋지만 쿼리 결과는 더 좋은 경우가 있다. 이는 Malware Semantic space의 구축 상태를 평가하기에 Auxiliary Task 의 정량 평가만으로는 부족하다는 것을 의미한다. 


\subsection{Querying Quantitative Test}
- metric performance measures
	- acc, precision, recall, auc, 등 label 겹치는 정도를 수치로 정량화
	- inner class variance 측정 후 센터로스 유무에 대해 비교. 
- Single label, Multi label, Centerloss(Mean, Add) , Weighted Center loss(Mean, Add)
- Train data querying , Valid data querying

앞서 Malware Semantic Space 란 사람이 중요하다고 생각하는 레이블이 많이 겹칠 수록 가까이 있도록, 그리고 그렇지 않을 수록 멀리 있도록 멀웨어 샘플들의 표현 벡터를 위치시킨 공간이라고 설명한 바 있다. 그리고 Malware Semantic Space 의 표현 벡터들을 이용하여 MIR 을 구축했을 때 중요한 레이블이 비슷한 샘플들을 검색할 수 있을 것이라고 했다. MWC Loss 를 사용하여 MIR System 을 구축했을 때 위의 정량 수치가 대체적으로 더 높다는 것은 곧 다른 Objective function 을 사용했을 때보다 Semantics 을 더 잘 학습했다고 볼 수 있고 이는 MIR System 의 Desired property 1 번인 Semantic Understanding 속성을 다른 로스들에 비해 더 만족시킨다.  


\subsection{Querying Qualitative Test}
\textbf{Visualizations.}
- PCA : Variance of inner class 가 작고 variance of inter class 가 크다는 것을 눈으로 보여줌. 더불어 주요 태그를 함께 보유하고 있다면 보틀넥이 가까운 곳에 위치함을 보여줌으로써 우리의 제안 방법을 통해 Malware Semantic space 가 구축되었다는 것을 보여줌.
vector space 에서 연산 관계가 있음을 보여줌.  

\textbf{Querying by malware sample. }
MWC 를 사용하여 학습시킨 MIR 시스템과 그렇지 않은 시스템에 대하여 멀웨어 샘플을 쿼링하여 얻은 top k 개의 결과를 리스팅하여 기재함으로써 MWC Loss 가 Malware Semantic space 를 구축하는데 도움이 된다는 것을 보여준다.


\textbf{Querying by labels. }
레이블들을 쿼링하여 동일 레이블 조합을 갖고 있는 top k 개의 결과를 리스팅하여 기재함으로써 단순히 Data retrieval system이 아니라 Information retrieval system 을 설계한 것이라는 것을 보여줌. 


\subsection{Center Vector Combination Methods}
Mean, Add 방법의 차이를 위의 결과들로부터 설명.

\textbf{add center vectors. } 



\subsection{Generalization}
입력 Feature 가 Semantics-aware feature 일 수록 새로운 샘플에 대한 Error 가 더 작다. 우리가 제안한 목적함수는 멀티 레이블과 레이블 별 중요도로부터 해당 샘플이 시멘틱 스페이스에서 어디에 위치해야하는지를 가이드해준다. 따라서 Train Samples 에 대해서는 데이터의 입력 Feature가 Semantic-aware 하지 않더라도 원하는 곳에 특징 표현 벡터를 위치시킬 수 있다. 하지만 새로 보는 샘플의 representation vector 가 우리가 원하는 곳에 위치하게 된다는 보장은 없다. 딥러닝의 하이러키컬 특징 표현 학습이 MWC loss 를 통해 가이드 되는 Semantic을 학습할 수 있도록 하려면 입력 Feature가 충분히 Semantics-aware 해야 하고, 이에 관련된 연구들은 섹션2에서 소개하였다. 

우리는 이 차이를 보이기 위해 semantics-aware level 이 다른 두 가지 피쳐에 대해 벡터 표현을 학습시키고, validation set 의 벡터 표현이 Semantic space 위에 잘 위치하는지 확인하는 실험을 한다. 첫 번째 실험에 사용되는 피쳐는 간단한 정적 분석을 통해 얻을 수 있는 Size, entropy\citep{} 이고, 두 번째 실험에 사용되는 피쳐는보다 조금 더 Semantics-aware 한 피쳐인 Thumbnail\citep{} 이다. 위에서 진행한 정량 평가와 정성 평가를 두 실험에 대해 진행해 본 결과 더 semantics-aware한 피쳐를 입력으로 사용할 수록 평가의 결과가 좋았고 이는 즉 Generalization 이 더 된다는 것을 의미한다. 즉, 누구라도 더 Semantics-aware한 피쳐를 입력으로 넣어줄 수 있다면, 간단히 Add-on 가능한 MWC loss 를 사용하여 훌륭한 Semantic space 를 구축할 수 있게 된다. 

% 시간이 된다면 APK Call-graph 도... 하면 좋을텐데..  

